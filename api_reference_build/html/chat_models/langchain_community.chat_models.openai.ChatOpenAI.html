

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>langchain_community.chat_models.openai.ChatOpenAI &mdash; ðŸ¦œðŸ”— LangChain 0.1.16</title>
  
  <link rel="canonical" href="https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.openai.ChatOpenAI.html" />

  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/autodoc_pydantic.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../langchain_api_reference.html">LangChain</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../core_api_reference.html">Core</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../community_api_reference.html">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../experimental_api_reference.html">Experimental</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../text_splitters_api_reference.html">Text splitters</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../ai21_api_reference.html">ai21</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../airbyte_api_reference.html">airbyte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../anthropic_api_reference.html">anthropic</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../astradb_api_reference.html">astradb</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../chroma_api_reference.html">chroma</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../cohere_api_reference.html">cohere</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../elasticsearch_api_reference.html">elasticsearch</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../exa_api_reference.html">exa</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../fireworks_api_reference.html">fireworks</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../google_genai_api_reference.html">google-genai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../google_vertexai_api_reference.html">google-vertexai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../groq_api_reference.html">groq</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../ibm_api_reference.html">ibm</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../mistralai_api_reference.html">mistralai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../mongodb_api_reference.html">mongodb</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../nomic_api_reference.html">nomic</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../nvidia_ai_endpoints_api_reference.html">nvidia-ai-endpoints</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../nvidia_trt_api_reference.html">nvidia-trt</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../openai_api_reference.html">openai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../pinecone_api_reference.html">pinecone</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../postgres_api_reference.html">postgres</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../robocorp_api_reference.html">robocorp</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../together_api_reference.html">together</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../upstage_api_reference.html">upstage</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../voyageai_api_reference.html">voyageai</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Partner libs</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../ai21_api_reference.html">ai21</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../airbyte_api_reference.html">airbyte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../anthropic_api_reference.html">anthropic</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../astradb_api_reference.html">astradb</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../chroma_api_reference.html">chroma</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../cohere_api_reference.html">cohere</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../elasticsearch_api_reference.html">elasticsearch</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../exa_api_reference.html">exa</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../fireworks_api_reference.html">fireworks</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../google_genai_api_reference.html">google-genai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../google_vertexai_api_reference.html">google-vertexai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../groq_api_reference.html">groq</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../ibm_api_reference.html">ibm</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../mistralai_api_reference.html">mistralai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../mongodb_api_reference.html">mongodb</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../nomic_api_reference.html">nomic</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../nvidia_ai_endpoints_api_reference.html">nvidia-ai-endpoints</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../nvidia_trt_api_reference.html">nvidia-trt</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../openai_api_reference.html">openai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../pinecone_api_reference.html">pinecone</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../postgres_api_reference.html">postgres</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../robocorp_api_reference.html">robocorp</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../together_api_reference.html">together</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../upstage_api_reference.html">upstage</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../voyageai_api_reference.html">voyageai</a>
          </div>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://python.langchain.com/">Docs</a>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Prev</a>
            <a href="#" role="button" class="btn sk-btn-rellink disabled py-1">Up</a>
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Next</a>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain_community.chat_models.openai</span></code>.ChatOpenAI</a><ul>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI</span></code></a><ul>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.cache"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.cache</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.callback_manager"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.callback_manager</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.callbacks"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.callbacks</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.custom_get_token_ids"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.custom_get_token_ids</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.default_headers"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.default_headers</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.default_query"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.default_query</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.http_client"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.http_client</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.max_retries"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.max_retries</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.max_tokens"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.max_tokens</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.metadata"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.metadata</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.model_kwargs"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.model_kwargs</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.model_name"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.model_name</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.n"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.n</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_api_base"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.openai_api_base</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_api_key"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.openai_api_key</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_organization"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.openai_organization</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_proxy"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.openai_proxy</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.request_timeout"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.request_timeout</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.streaming"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.streaming</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.tags"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.tags</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.temperature"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.temperature</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.tiktoken_model_name"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.tiktoken_model_name</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.verbose"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.verbose</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.__call__"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.__call__()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.abatch"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.abatch()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.abatch_as_completed"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.abatch_as_completed()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.agenerate"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.agenerate()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.agenerate_prompt"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.agenerate_prompt()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.ainvoke"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.ainvoke()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.apredict"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.apredict()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.apredict_messages"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.apredict_messages()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.assign"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.assign()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.astream"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.astream()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.astream_events"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.astream_events()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.astream_log"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.astream_log()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.atransform"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.atransform()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.batch"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.batch()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.batch_as_completed"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.batch_as_completed()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.bind"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.bind()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.bind_functions"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.bind_functions()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.bind_tools"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.bind_tools()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.call_as_llm"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.call_as_llm()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.completion_with_retry"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.completion_with_retry()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.config_schema"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.config_schema()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.configurable_alternatives"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.configurable_alternatives()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.configurable_fields"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.configurable_fields()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.construct"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.construct()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.copy"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.copy()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.dict"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.dict()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.from_orm"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.from_orm()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.generate"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.generate()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.generate_prompt"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.generate_prompt()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_graph"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_graph()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_input_schema"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_input_schema()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_lc_namespace"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_lc_namespace()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_name"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_name()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_num_tokens"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_num_tokens()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_num_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_num_tokens_from_messages()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_output_schema"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_output_schema()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_prompts"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_prompts()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.get_token_ids"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.get_token_ids()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.invoke"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.invoke()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.is_lc_serializable"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.is_lc_serializable()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.json"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.json()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.lc_id"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.lc_id()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.map"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.map()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.parse_file"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.parse_file()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.parse_obj"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.parse_obj()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.parse_raw"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.parse_raw()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.pick"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.pick()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.pipe"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.pipe()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.predict"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.predict()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.predict_messages"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.predict_messages()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.schema"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.schema()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.schema_json"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.schema_json()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.stream"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.stream()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.to_json"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.to_json()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.to_json_not_implemented"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.to_json_not_implemented()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.transform"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.transform()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.update_forward_refs"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.update_forward_refs()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.validate"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.validate()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.with_config"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.with_config()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.with_fallbacks"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.with_fallbacks()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.with_listeners"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.with_listeners()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.with_retry"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.with_retry()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.with_structured_output"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.with_structured_output()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.with_types"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.with_types()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.InputType"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.InputType</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.OutputType"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.OutputType</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.config_specs"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.config_specs</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.input_schema"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.input_schema</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.lc_attributes"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.lc_attributes</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.lc_secrets"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.lc_secrets</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.name"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.name</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.openai.ChatOpenAI.output_schema"><code class="docutils literal notranslate"><span class="pre">ChatOpenAI.output_schema</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="langchain-community-chat-models-openai-chatopenai">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain_community.chat_models.openai</span></code>.ChatOpenAI<a class="headerlink" href="#langchain-community-chat-models-openai-chatopenai" title="Permalink to this heading">Â¶</a></h1>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain_community.chat_models.openai.</span></span><span class="sig-name descname"><span class="pre">ChatOpenAI</span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel" title="langchain_core.language_models.chat_models.BaseChatModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseChatModel</span></code></a></p>
<p>[<em>Deprecated</em>] <cite>OpenAI</cite> Chat large language models API.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the openai.create call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="n">openai</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.0.10.</span></p>
</div>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.cache">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../caches/langchain_core.caches.BaseCache.html#langchain_core.caches.BaseCache" title="langchain_core.caches.BaseCache"><span class="pre">BaseCache</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.cache" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Whether to cache the response.</p>
<ul class="simple">
<li><p>If true, will use the global cache.</p></li>
<li><p>If false, will not use a cache</p></li>
<li><p>If None, will use the global cache if itâ€™s set, otherwise no cache.</p></li>
<li><p>If instance of BaseCache, will use the provided cache.</p></li>
</ul>
<p>Caching is not currently supported for streaming methods of models.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.callback_manager">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">callback_manager</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.callback_manager" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[DEPRECATED] Callback manager to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.callbacks">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">callbacks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callbacks</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.callbacks" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Callbacks to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.custom_get_token_ids">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">custom_get_token_ids</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.custom_get_token_ids" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Optional encoder to use for counting tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.default_headers">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_headers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.default_headers" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.default_query">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_query</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.default_query" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.http_client">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">http_client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.http_client" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Optional httpx.Client.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.max_retries">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.max_retries" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.max_tokens">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.max_tokens" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.metadata">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.metadata" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Metadata to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.model_kwargs">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.model_kwargs" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.model_name">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt-3.5-turbo'</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'model')</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.model_name" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.n">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.n" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Number of chat completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.openai_api_base">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_api_base</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'base_url')</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_api_base" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base URL path for API requests, leave blank if not using a proxy or service
emulator.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.openai_api_key">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'api_key')</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_api_key" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Automatically inferred from env var <cite>OPENAI_API_KEY</cite> if not provided.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.openai_organization">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_organization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'organization')</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_organization" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Automatically inferred from env var <cite>OPENAI_ORG_ID</cite> if not provided.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.openai_proxy">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_proxy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.openai_proxy" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.request_timeout">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'timeout')</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.request_timeout" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Timeout for requests to OpenAI completion API. Can be float, httpx.Timeout or
None.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.streaming">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.streaming" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.tags">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.tags" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Tags to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.temperature">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.temperature" title="Permalink to this definition">Â¶</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.tiktoken_model_name">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tiktoken_model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.tiktoken_model_name" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The model name to pass to tiktoken when using this class.
Tiktoken is used to count the number of tokens in documents to constrain
them to be under a certain limit. By default, when set to None, this will
be the same as the embedding model name. However, there are some cases
where you may want to use this Embedding class with a model name not
supported by tiktoken. This can include when using Azure embeddings or
when using one of the many model providers that expose an OpenAI-like
API but with different models. In those cases, in order to avoid erroring
when tiktoken is called, you can specify a model name to use here.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.verbose">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.verbose" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.abatch">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">abatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.abatch" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation runs ainvoke in parallel using asyncio.gather.</p>
<p>The default implementation of batch works well for IO bound runnables.</p>
<p>Subclasses should override this method if they can batch more efficiently;
e.g., if the underlying runnable uses an API which supports a batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>Input</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.abatch_as_completed">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">abatch_as_completed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Exception</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.abatch_as_completed" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Run ainvoke in parallel on a list of inputs,
yielding results as they complete.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>Input</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>AsyncIterator</em>[<em>Tuple</em>[int, <em>Union</em>[<em>Output</em>, Exception]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">UUID</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.agenerate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Asynchronously pass a sequence of prompts to a model and return generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em><em>]</em>) â€“ List of list of messages.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) â€“ Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>metadata</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>run_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>run_id</strong> (<em>Optional</em><em>[</em><em>UUID</em><em>]</em>) â€“ </p></li>
<li><p><strong>**kwargs</strong> â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.agenerate_prompt" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Asynchronously pass a sequence of prompts and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a><em>]</em>) â€“ List of PromptValues. A PromptValue is an object that can be
converted to match the format of any language model (string for pure
text generation models and BaseMessages for chat models).</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) â€“ Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.ainvoke">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ainvoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LanguageModelInput</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.ainvoke" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation of ainvoke, calls invoke from a thread.</p>
<p>The default implementation allows usage of async code even if
the runnable did not implement a native async version of invoke.</p>
<p>Subclasses should override this method if they can run asynchronously.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>LanguageModelInput</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage">BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.apredict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use ainvoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.apredict_messages" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use ainvoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.assign">
<span class="sig-name descname"><span class="pre">assign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.assign" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Assigns new fields to the dict output of this runnable.
Returns a new runnable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.llms.fake</span> <span class="kn">import</span> <span class="n">FakeStreamingListLLM</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">SystemMessagePromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">Runnable</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SystemMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;You are a nice assistant.&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="s2">&quot;</span><span class="si">{question}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">FakeStreamingListLLM</span><span class="p">(</span><span class="n">responses</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;foo-lish&quot;</span><span class="p">])</span>

<span class="n">chain</span><span class="p">:</span> <span class="n">Runnable</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span> <span class="o">|</span> <span class="p">{</span><span class="s2">&quot;str&quot;</span><span class="p">:</span> <span class="n">StrOutputParser</span><span class="p">()}</span>

<span class="n">chain_with_assign</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">hello</span><span class="o">=</span><span class="n">itemgetter</span><span class="p">(</span><span class="s2">&quot;str&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">llm</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">chain_with_assign</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">schema</span><span class="p">())</span>
<span class="c1"># {&#39;title&#39;: &#39;PromptInput&#39;, &#39;type&#39;: &#39;object&#39;, &#39;properties&#39;:</span>
<span class="p">{</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;Question&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">}}}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chain_with_assign</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">schema</span><span class="p">())</span> <span class="c1">#</span>
<span class="p">{</span><span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;RunnableSequenceOutput&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;properties&#39;</span><span class="p">:</span>
<span class="p">{</span><span class="s1">&#39;str&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;Str&#39;</span><span class="p">,</span>
<span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">},</span> <span class="s1">&#39;hello&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;Hello&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">}}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>]</em><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Any</em>, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.astream">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">astream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LanguageModelInput</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessageChunk.html#langchain_core.messages.base.BaseMessageChunk" title="langchain_core.messages.base.BaseMessageChunk"><span class="pre">BaseMessageChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.astream" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation of astream, which calls ainvoke.
Subclasses should override this method if they support streaming output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>LanguageModelInput</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>AsyncIterator[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessageChunk.html#langchain_core.messages.base.BaseMessageChunk" title="langchain_core.messages.base.BaseMessageChunk">BaseMessageChunk</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.astream_events">
<span class="sig-name descname"><span class="pre">astream_events</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'v1'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.schema.StreamEvent.html#langchain_core.runnables.schema.StreamEvent" title="langchain_core.runnables.schema.StreamEvent"><span class="pre">StreamEvent</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.astream_events" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Beta</em>] Generate a stream of events.</p>
<p>Use to create an iterator over StreamEvents that provide real-time information
about the progress of the runnable, including StreamEvents from intermediate
results.</p>
<p>A StreamEvent is a dictionary with the following schema:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">event</span></code>: <strong>str</strong> - Event names are of the</dt><dd><p>format: on_[runnable_type]_(start|stream|end).</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: <strong>str</strong> - The name of the runnable that generated the event.</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">run_id</span></code>: <strong>str</strong> - randomly generated ID associated with the given execution of</dt><dd><p>the runnable that emitted the event.
A child runnable that gets invoked as part of the execution of a
parent runnable is assigned its own unique ID.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">tags</span></code>: <strong>Optional[List[str]]</strong> - The tags of the runnable that generated</dt><dd><p>the event.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">metadata</span></code>: <strong>Optional[Dict[str, Any]]</strong> - The metadata of the runnable</dt><dd><p>that generated the event.</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: <strong>Dict[str, Any]</strong></p></li>
</ul>
<p>Below is a table that illustrates some evens that might be emitted by various
chains. Metadata fields have been omitted from the table for brevity.
Chain definitions have been included after the table.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 11%" />
<col style="width: 20%" />
<col style="width: 28%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>event</p></th>
<th class="head"><p>name</p></th>
<th class="head"><p>chunk</p></th>
<th class="head"><p>input</p></th>
<th class="head"><p>output</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>on_chat_model_start</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{â€œmessagesâ€: [[SystemMessage, HumanMessage]]}</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_chat_model_stream</p></td>
<td><p>[model name]</p></td>
<td><p>AIMessageChunk(content=â€helloâ€)</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chat_model_end</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{â€œmessagesâ€: [[SystemMessage, HumanMessage]]}</p></td>
<td><p>{â€œgenerationsâ€: [â€¦], â€œllm_outputâ€: None, â€¦}</p></td>
</tr>
<tr class="row-odd"><td><p>on_llm_start</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{â€˜inputâ€™: â€˜helloâ€™}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_llm_stream</p></td>
<td><p>[model name]</p></td>
<td><p>â€˜Helloâ€™</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_llm_end</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>â€˜Hello human!â€™</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chain_start</p></td>
<td><p>format_docs</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_chain_stream</p></td>
<td><p>format_docs</p></td>
<td><p>â€œhello world!, goodbye world!â€</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chain_end</p></td>
<td><p>format_docs</p></td>
<td></td>
<td><p>[Document(â€¦)]</p></td>
<td><p>â€œhello world!, goodbye world!â€</p></td>
</tr>
<tr class="row-odd"><td><p>on_tool_start</p></td>
<td><p>some_tool</p></td>
<td></td>
<td><p>{â€œxâ€: 1, â€œyâ€: â€œ2â€}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_tool_stream</p></td>
<td><p>some_tool</p></td>
<td><p>{â€œxâ€: 1, â€œyâ€: â€œ2â€}</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_tool_end</p></td>
<td><p>some_tool</p></td>
<td></td>
<td></td>
<td><p>{â€œxâ€: 1, â€œyâ€: â€œ2â€}</p></td>
</tr>
<tr class="row-even"><td><p>on_retriever_start</p></td>
<td><p>[retriever name]</p></td>
<td></td>
<td><p>{â€œqueryâ€: â€œhelloâ€}</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_retriever_chunk</p></td>
<td><p>[retriever name]</p></td>
<td><p>{documents: [â€¦]}</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_retriever_end</p></td>
<td><p>[retriever name]</p></td>
<td></td>
<td><p>{â€œqueryâ€: â€œhelloâ€}</p></td>
<td><p>{documents: [â€¦]}</p></td>
</tr>
<tr class="row-odd"><td><p>on_prompt_start</p></td>
<td><p>[template_name]</p></td>
<td></td>
<td><p>{â€œquestionâ€: â€œhelloâ€}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_prompt_end</p></td>
<td><p>[template_name]</p></td>
<td></td>
<td><p>{â€œquestionâ€: â€œhelloâ€}</p></td>
<td><p>ChatPromptValue(messages: [SystemMessage, â€¦])</p></td>
</tr>
</tbody>
</table>
<p>Here are declarations associated with the events shown above:</p>
<p><cite>format_docs</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">format_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Format the docs.&#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">])</span>

<span class="n">format_docs</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">format_docs</span><span class="p">)</span>
</pre></div>
</div>
<p><cite>some_tool</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tool</span>
<span class="k">def</span> <span class="nf">some_tool</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Some_tool.&#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>
</pre></div>
</div>
<p><cite>prompt</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are Cat Agent 007&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{question}</span><span class="s2">&quot;</span><span class="p">)]</span>
<span class="p">)</span><span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;run_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my_template&quot;</span><span class="p">,</span> <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;my_template&quot;</span><span class="p">]})</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">s</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">reverse</span><span class="p">)</span>

<span class="n">events</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">event</span> <span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">chain</span><span class="o">.</span><span class="n">astream_events</span><span class="p">(</span><span class="s2">&quot;hello&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s2">&quot;v1&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># will produce the following events (run_id has been omitted for brevity):</span>
<span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hello&quot;</span><span class="p">},</span>
        <span class="s2">&quot;event&quot;</span><span class="p">:</span> <span class="s2">&quot;on_chain_start&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;chunk&quot;</span><span class="p">:</span> <span class="s2">&quot;olleh&quot;</span><span class="p">},</span>
        <span class="s2">&quot;event&quot;</span><span class="p">:</span> <span class="s2">&quot;on_chain_stream&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;olleh&quot;</span><span class="p">},</span>
        <span class="s2">&quot;event&quot;</span><span class="p">:</span> <span class="s2">&quot;on_chain_end&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Any</em>) â€“ The input to the runnable.</p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ The config to use for the runnable.</p></li>
<li><p><strong>version</strong> (<em>Literal</em><em>[</em><em>'v1'</em><em>]</em>) â€“ The version of the schema to use.
Currently only version 1 is available.
No default will be assigned until the API is stabilized.</p></li>
<li><p><strong>include_names</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Only include events from runnables with matching names.</p></li>
<li><p><strong>include_types</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Only include events from runnables with matching types.</p></li>
<li><p><strong>include_tags</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Only include events from runnables with matching tags.</p></li>
<li><p><strong>exclude_names</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Exclude events from runnables with matching names.</p></li>
<li><p><strong>exclude_types</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Exclude events from runnables with matching types.</p></li>
<li><p><strong>exclude_tags</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Exclude events from runnables with matching tags.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ Additional keyword arguments to pass to the runnable.
These will be passed to astream_log as this implementation
of astream_events is built on top of astream_log.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An async stream of StreamEvents.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>AsyncIterator</em>[<a class="reference internal" href="../runnables/langchain_core.runnables.schema.StreamEvent.html#langchain_core.runnables.schema.StreamEvent" title="langchain_core.runnables.schema.StreamEvent"><em>StreamEvent</em></a>]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.astream_log">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">astream_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diff</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_streamed_output_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../tracers/langchain_core.tracers.log_stream.RunLogPatch.html#langchain_core.tracers.log_stream.RunLogPatch" title="langchain_core.tracers.log_stream.RunLogPatch"><span class="pre">RunLogPatch</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../tracers/langchain_core.tracers.log_stream.RunLog.html#langchain_core.tracers.log_stream.RunLog" title="langchain_core.tracers.log_stream.RunLog"><span class="pre">RunLog</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.astream_log" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Stream all output from a runnable, as reported to the callback system.
This includes all inner runs of LLMs, Retrievers, Tools, etc.</p>
<p>Output is streamed as Log objects, which include a list of
jsonpatch ops that describe how the state of the run has changed in each
step, and the final state of the run.</p>
<p>The jsonpatch ops can be applied in order to construct state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Any</em>) â€“ The input to the runnable.</p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ The config to use for the runnable.</p></li>
<li><p><strong>diff</strong> (<em>bool</em>) â€“ Whether to yield diffs between each step, or the current state.</p></li>
<li><p><strong>with_streamed_output_list</strong> (<em>bool</em>) â€“ Whether to yield the streamed_output list.</p></li>
<li><p><strong>include_names</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Only include logs with these names.</p></li>
<li><p><strong>include_types</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Only include logs with these types.</p></li>
<li><p><strong>include_tags</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Only include logs with these tags.</p></li>
<li><p><strong>exclude_names</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Exclude logs with these names.</p></li>
<li><p><strong>exclude_types</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Exclude logs with these types.</p></li>
<li><p><strong>exclude_tags</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Exclude logs with these tags.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Union[AsyncIterator[<a class="reference internal" href="../tracers/langchain_core.tracers.log_stream.RunLogPatch.html#langchain_core.tracers.log_stream.RunLogPatch" title="langchain_core.tracers.log_stream.RunLogPatch">RunLogPatch</a>], AsyncIterator[<a class="reference internal" href="../tracers/langchain_core.tracers.log_stream.RunLog.html#langchain_core.tracers.log_stream.RunLog" title="langchain_core.tracers.log_stream.RunLog">RunLog</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.atransform">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">atransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.atransform" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation of atransform, which buffers input and calls astream.
Subclasses should override this method if they can start producing output while
input is still being generated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>AsyncIterator</em><em>[</em><em>Input</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>AsyncIterator</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.batch">
<span class="sig-name descname"><span class="pre">batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.batch" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation runs invoke in parallel using a thread pool executor.</p>
<p>The default implementation of batch works well for IO bound runnables.</p>
<p>Subclasses should override this method if they can batch more efficiently;
e.g., if the underlying runnable uses an API which supports a batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>Input</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.batch_as_completed">
<span class="sig-name descname"><span class="pre">batch_as_completed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Exception</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.batch_as_completed" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Run invoke in parallel on a list of inputs,
yielding results as they complete.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>Input</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Iterator</em>[<em>Tuple</em>[int, <em>Union</em>[<em>Output</em>, Exception]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.bind">
<span class="sig-name descname"><span class="pre">bind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.bind" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bind arguments to a Runnable, returning a new Runnable.</p>
<p>Useful when a runnable in a chain requires an argument that is not
in the output of the previous runnable or included in the user input.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.chat_models</span> <span class="kn">import</span> <span class="n">ChatOllama</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOllama</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;llama2&#39;</span><span class="p">)</span>

<span class="c1"># Without bind.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">llm</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Repeat quoted words exactly: &#39;One two three four five.&#39;&quot;</span><span class="p">)</span>
<span class="c1"># Output is &#39;One two three four five.&#39;</span>

<span class="c1"># With bind.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">llm</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;three&quot;</span><span class="p">])</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Repeat quoted words exactly: &#39;One two three four five.&#39;&quot;</span><span class="p">)</span>
<span class="c1"># Output is &#39;One two&#39;</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.bind_functions">
<span class="sig-name descname"><span class="pre">bind_functions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">function_call</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI.bind_functions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.bind_functions" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bind functions (and other objects) to this chat model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>functions</strong> (<em>Sequence</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Type</em><em>[</em><em>BaseModel</em><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) â€“ A list of function definitions to bind to this chat model.
Can be  a dictionary, pydantic model, or callable. Pydantic
models and callables will be automatically converted to
their schema dictionary representation.</p></li>
<li><p><strong>function_call</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ Which function to require the model to call.
Must be the name of the single provided function or
â€œautoâ€ to automatically determine which function to call
(if any).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ Any additional parameters to pass to the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span></code> constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Union</em>[<a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a>, str, <em>Sequence</em>[<em>Union</em>[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>, <em>Tuple</em>[str, str], str, <em>Dict</em>[str, <em>Any</em>]]]], <a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.bind_tools">
<span class="sig-name descname"><span class="pre">bind_tools</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tools</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../video_captioning/langchain_experimental.video_captioning.models.BaseModel.html#langchain_experimental.video_captioning.models.BaseModel" title="langchain_experimental.video_captioning.models.BaseModel"><span class="pre">BaseModel</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool" title="langchain_core.tools.BaseTool"><span class="pre">BaseTool</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">LanguageModelInput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.bind_tools" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tools</strong> (<em>Sequence</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Type</em><em>[</em><a class="reference internal" href="../video_captioning/langchain_experimental.video_captioning.models.BaseModel.html#langchain_experimental.video_captioning.models.BaseModel" title="langchain_experimental.video_captioning.models.BaseModel"><em>BaseModel</em></a><em>]</em><em>, </em><em>Callable</em><em>, </em><a class="reference internal" href="../tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool" title="langchain_core.tools.BaseTool"><em>BaseTool</em></a><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable">Runnable</a>[LanguageModelInput, <a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage">BaseMessage</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.call_as_llm">
<span class="sig-name descname"><span class="pre">call_as_llm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.call_as_llm" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>message</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.completion_with_retry">
<span class="sig-name descname"><span class="pre">completion_with_retry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_manager</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.manager.CallbackManagerForLLMRun.html#langchain_core.callbacks.manager.CallbackManagerForLLMRun" title="langchain_core.callbacks.manager.CallbackManagerForLLMRun"><span class="pre">CallbackManagerForLLMRun</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI.completion_with_retry"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.completion_with_retry" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Use tenacity to retry the completion call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>run_manager</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.manager.CallbackManagerForLLMRun.html#langchain_core.callbacks.manager.CallbackManagerForLLMRun" title="langchain_core.callbacks.manager.CallbackManagerForLLMRun"><em>CallbackManagerForLLMRun</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Any</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.config_schema">
<span class="sig-name descname"><span class="pre">config_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.config_schema" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The type of config this runnable accepts specified as a pydantic model.</p>
<p>To mark a field as configurable, see the <cite>configurable_fields</cite>
and <cite>configurable_alternatives</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ A list of fields to include in the config schema.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A pydantic model that can be used to validate config.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Type</em>[<em>BaseModel</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.configurable_alternatives">
<span class="sig-name descname"><span class="pre">configurable_alternatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><span class="pre">ConfigurableField</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.configurable_alternatives" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Configure alternatives for runnables that can be set at runtime.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_anthropic</span> <span class="kn">import</span> <span class="n">ChatAnthropic</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables.utils</span> <span class="kn">import</span> <span class="n">ConfigurableField</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;claude-3-sonnet-20240229&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">configurable_alternatives</span><span class="p">(</span>
    <span class="n">ConfigurableField</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;llm&quot;</span><span class="p">),</span>
    <span class="n">default_key</span><span class="o">=</span><span class="s2">&quot;anthropic&quot;</span><span class="p">,</span>
    <span class="n">openai</span><span class="o">=</span><span class="n">ChatOpenAI</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># uses the default model ChatAnthropic</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;which organization created you?&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># uses ChatOpenaAI</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
        <span class="n">configurable</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;llm&quot;</span><span class="p">:</span> <span class="s2">&quot;openai&quot;</span><span class="p">}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;which organization created you?&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>which</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><em>ConfigurableField</em></a>) â€“ </p></li>
<li><p><strong>default_key</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>prefix_keys</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.configurable_fields">
<span class="sig-name descname"><span class="pre">configurable_fields</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><span class="pre">ConfigurableField</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html#langchain_core.runnables.utils.ConfigurableFieldSingleOption" title="langchain_core.runnables.utils.ConfigurableFieldSingleOption"><span class="pre">ConfigurableFieldSingleOption</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html#langchain_core.runnables.utils.ConfigurableFieldMultiOption" title="langchain_core.runnables.utils.ConfigurableFieldMultiOption"><span class="pre">ConfigurableFieldMultiOption</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.configurable_fields" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Configure particular runnable fields at runtime.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">ConfigurableField</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">configurable_fields</span><span class="p">(</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">ConfigurableField</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;output_token_number&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Max tokens in the output&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The maximum number of tokens in the output&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># max_tokens = 20</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;max_tokens_20: &quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;tell me something about chess&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>

<span class="c1"># max_tokens = 200</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;max_tokens_200: &quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">configurable</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;output_token_number&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;tell me something about chess&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><em>ConfigurableField</em></a><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html#langchain_core.runnables.utils.ConfigurableFieldSingleOption" title="langchain_core.runnables.utils.ConfigurableFieldSingleOption"><em>ConfigurableFieldSingleOption</em></a><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html#langchain_core.runnables.utils.ConfigurableFieldMultiOption" title="langchain_core.runnables.utils.ConfigurableFieldMultiOption"><em>ConfigurableFieldMultiOption</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">SetStr</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.construct" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractSetIntStr</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MappingIntStrAny</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractSetIntStr</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MappingIntStrAny</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DictStrAny</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.copy" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.from_orm">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_orm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.from_orm" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">UUID</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.generate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pass a sequence of prompts to the model and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em><em>]</em>) â€“ List of list of messages.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) â€“ Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>metadata</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>run_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>run_id</strong> (<em>Optional</em><em>[</em><em>UUID</em><em>]</em>) â€“ </p></li>
<li><p><strong>**kwargs</strong> â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.generate_prompt" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pass a sequence of prompts to the model and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a><em>]</em>) â€“ List of PromptValues. A PromptValue is an object that can be
converted to match the format of any language model (string for pure
text generation models and BaseMessages for chat models).</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) â€“ Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_graph">
<span class="sig-name descname"><span class="pre">get_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.graph.Graph.html#langchain_core.runnables.graph.Graph" title="langchain_core.runnables.graph.Graph"><span class="pre">Graph</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_graph" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a graph representation of this runnable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.graph.Graph.html#langchain_core.runnables.graph.Graph" title="langchain_core.runnables.graph.Graph"><em>Graph</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_input_schema">
<span class="sig-name descname"><span class="pre">get_input_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_input_schema" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get a pydantic model that can be used to validate input to the runnable.</p>
<p>Runnables that leverage the configurable_fields and configurable_alternatives
methods will have a dynamic input schema that depends on which
configuration the runnable is invoked with.</p>
<p>This method allows to get an input schema for a specific configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ A config to use when generating the schema.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A pydantic model that can be used to validate input.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Type</em>[<em>BaseModel</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_lc_namespace">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_lc_namespace</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI.get_lc_namespace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_lc_namespace" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the namespace of the langchain object.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_name">
<span class="sig-name descname"><span class="pre">get_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">suffix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_name" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the name of the runnable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>suffix</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_num_tokens" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<p>Useful for checking if an input will fit in a modelâ€™s context window.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ The string input to tokenize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The integer number of tokens in the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI.get_num_tokens_from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_num_tokens_from_messages" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Calculate num tokens for gpt-3.5-turbo and gpt-4 with tiktoken package.</p>
<p>Official documentation: <a class="reference external" href="https://github.com/openai/openai-cookbook/blob/">https://github.com/openai/openai-cookbook/blob/</a>
main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_output_schema">
<span class="sig-name descname"><span class="pre">get_output_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_output_schema" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get a pydantic model that can be used to validate output to the runnable.</p>
<p>Runnables that leverage the configurable_fields and configurable_alternatives
methods will have a dynamic output schema that depends on which
configuration the runnable is invoked with.</p>
<p>This method allows to get an output schema for a specific configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ A config to use when generating the schema.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A pydantic model that can be used to validate output.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Type</em>[<em>BaseModel</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_prompts">
<span class="sig-name descname"><span class="pre">get_prompts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompts/langchain_core.prompts.base.BasePromptTemplate.html#langchain_core.prompts.base.BasePromptTemplate" title="langchain_core.prompts.base.BasePromptTemplate"><span class="pre">BasePromptTemplate</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_prompts" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List[<a class="reference internal" href="../prompts/langchain_core.prompts.base.BasePromptTemplate.html#langchain_core.prompts.base.BasePromptTemplate" title="langchain_core.prompts.base.BasePromptTemplate">BasePromptTemplate</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI.get_token_ids"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.get_token_ids" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the tokens present in the text with tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.invoke">
<span class="sig-name descname"><span class="pre">invoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LanguageModelInput</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.invoke" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Transform a single input into an output. Override to implement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>LanguageModelInput</em>) â€“ The input to the runnable.</p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ A config to use when invoking the runnable.
The config supports standard keys like â€˜tagsâ€™, â€˜metadataâ€™ for tracing
purposes, â€˜max_concurrencyâ€™ for controlling how much work to do
in parallel, and other keys. Please refer to the RunnableConfig
for more details.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The output of the runnable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage">BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.is_lc_serializable">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_lc_serializable</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/openai.html#ChatOpenAI.is_lc_serializable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.is_lc_serializable" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return whether this model can be serialized by Langchain.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractSetIntStr</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MappingIntStrAny</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractSetIntStr</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">MappingIntStrAny</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">unicode</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.json" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.lc_id">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_id</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.lc_id" title="Permalink to this definition">Â¶</a></dt>
<dd><p>A unique identifier for this class for serialization purposes.</p>
<p>The unique identifier is a list of strings that describes the path
to the object.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.map">
<span class="sig-name descname"><span class="pre">map</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.map" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a new Runnable that maps a list of inputs to a list of outputs,
by calling invoke() with each input.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">runnable</span><span class="o">.</span><span class="n">map</span><span class="p">()</span><span class="o">.</span><span class="n">invoke</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span> <span class="c1"># [2, 3, 4]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>List</em>[<em>Input</em>], <em>List</em>[<em>Output</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.parse_file">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">content_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">unicode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">unicode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'utf8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proto</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Protocol</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_pickle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.parse_file" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Path</em><em>]</em>) â€“ </p></li>
<li><p><strong>content_type</strong> (<em>unicode</em>) â€“ </p></li>
<li><p><strong>encoding</strong> (<em>unicode</em>) â€“ </p></li>
<li><p><strong>proto</strong> (<em>Protocol</em>) â€“ </p></li>
<li><p><strong>allow_pickle</strong> (<em>bool</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.parse_obj">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse_obj</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.parse_obj" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.parse_raw">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse_raw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bytes</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">content_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">unicode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">unicode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'utf8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proto</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Protocol</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_pickle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.parse_raw" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>bytes</em><em>]</em>) â€“ </p></li>
<li><p><strong>content_type</strong> (<em>unicode</em>) â€“ </p></li>
<li><p><strong>encoding</strong> (<em>unicode</em>) â€“ </p></li>
<li><p><strong>proto</strong> (<em>Protocol</em>) â€“ </p></li>
<li><p><strong>allow_pickle</strong> (<em>bool</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.pick">
<span class="sig-name descname"><span class="pre">pick</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.pick" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pick keys from the dict output of this runnable.</p>
<dl>
<dt>Pick single key:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span><span class="p">,</span> <span class="n">RunnableMap</span>

<span class="n">as_str</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">as_json</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">RunnableMap</span><span class="p">(</span><span class="nb">str</span><span class="o">=</span><span class="n">as_str</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">as_json</span><span class="p">)</span>

<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;[1, 2, 3]&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; {&quot;str&quot;: &quot;[1, 2, 3]&quot;, &quot;json&quot;: [1, 2, 3]}</span>

<span class="n">json_only_chain</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">pick</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span>
<span class="n">json_only_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;[1, 2, 3]&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; [1, 2, 3]</span>
</pre></div>
</div>
</dd>
<dt>Pick list of keys:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span><span class="p">,</span> <span class="n">RunnableMap</span>

<span class="n">as_str</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">as_json</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">as_bytes</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">RunnableMap</span><span class="p">(</span>
    <span class="nb">str</span><span class="o">=</span><span class="n">as_str</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="n">as_json</span><span class="p">,</span>
    <span class="nb">bytes</span><span class="o">=</span><span class="n">RunnableLambda</span><span class="p">(</span><span class="n">as_bytes</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;[1, 2, 3]&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; {&quot;str&quot;: &quot;[1, 2, 3]&quot;, &quot;json&quot;: [1, 2, 3], &quot;bytes&quot;: b&quot;[1, 2, 3]&quot;}</span>

<span class="n">json_and_bytes_chain</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">pick</span><span class="p">([</span><span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;bytes&quot;</span><span class="p">])</span>
<span class="n">json_and_bytes_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;[1, 2, 3]&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; {&quot;json&quot;: [1, 2, 3], &quot;bytes&quot;: b&quot;[1, 2, 3]&quot;}</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keys</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Any</em>, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.pipe">
<span class="sig-name descname"><span class="pre">pipe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">others</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Other</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Other</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Other</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.pipe" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Compose this Runnable with Runnable-like objects to make a RunnableSequence.</p>
<p>Equivalent to <cite>RunnableSequence(self, *others)</cite> or <cite>self | others[0] | â€¦</cite></p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">def</span> <span class="nf">add_one</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">mul_two</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>

<span class="n">runnable_1</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">add_one</span><span class="p">)</span>
<span class="n">runnable_2</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">mul_two</span><span class="p">)</span>
<span class="n">sequence</span> <span class="o">=</span> <span class="n">runnable_1</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">runnable_2</span><span class="p">)</span>
<span class="c1"># Or equivalently:</span>
<span class="c1"># sequence = runnable_1 | runnable_2</span>
<span class="c1"># sequence = RunnableSequence(first=runnable_1, last=runnable_2)</span>
<span class="n">sequence</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">await</span> <span class="n">sequence</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># -&gt; 4</span>

<span class="n">sequence</span><span class="o">.</span><span class="n">batch</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="k">await</span> <span class="n">sequence</span><span class="o">.</span><span class="n">abatch</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="c1"># -&gt; [4, 6, 8]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>others</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Any</em><em>, </em><em>Other</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Other</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Input</em>, <em>Other</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.predict_messages" title="Permalink to this definition">Â¶</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_template</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">unicode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'#/definitions/{model}'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DictStrAny</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.schema" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>ref_template</strong> (<em>unicode</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>DictStrAny</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.schema_json">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">schema_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_template</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">unicode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'#/definitions/{model}'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">unicode</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.schema_json" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>ref_template</strong> (<em>unicode</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LanguageModelInput</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessageChunk.html#langchain_core.messages.base.BaseMessageChunk" title="langchain_core.messages.base.BaseMessageChunk"><span class="pre">BaseMessageChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.stream" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation of stream, which calls invoke.
Subclasses should override this method if they support streaming output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>LanguageModelInput</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Iterator[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessageChunk.html#langchain_core.messages.base.BaseMessageChunk" title="langchain_core.messages.base.BaseMessageChunk">BaseMessageChunk</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedConstructor.html#langchain_core.load.serializable.SerializedConstructor" title="langchain_core.load.serializable.SerializedConstructor"><span class="pre">SerializedConstructor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedNotImplemented.html#langchain_core.load.serializable.SerializedNotImplemented" title="langchain_core.load.serializable.SerializedNotImplemented"><span class="pre">SerializedNotImplemented</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.to_json" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Serialize the runnable to JSON.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Union</em>[<a class="reference internal" href="../load/langchain_core.load.serializable.SerializedConstructor.html#langchain_core.load.serializable.SerializedConstructor" title="langchain_core.load.serializable.SerializedConstructor"><em>SerializedConstructor</em></a>, <a class="reference internal" href="../load/langchain_core.load.serializable.SerializedNotImplemented.html#langchain_core.load.serializable.SerializedNotImplemented" title="langchain_core.load.serializable.SerializedNotImplemented"><em>SerializedNotImplemented</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.to_json_not_implemented">
<span class="sig-name descname"><span class="pre">to_json_not_implemented</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedNotImplemented.html#langchain_core.load.serializable.SerializedNotImplemented" title="langchain_core.load.serializable.SerializedNotImplemented"><span class="pre">SerializedNotImplemented</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.to_json_not_implemented" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedNotImplemented.html#langchain_core.load.serializable.SerializedNotImplemented" title="langchain_core.load.serializable.SerializedNotImplemented"><em>SerializedNotImplemented</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.transform" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Default implementation of transform, which buffers input and then calls stream.
Subclasses should override this method if they can start producing output while
input is still being generated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Iterator</em><em>[</em><em>Input</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Iterator</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.update_forward_refs" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.validate">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.validate" title="Permalink to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.with_config" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bind config to a Runnable, returning a new Runnable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.with_fallbacks">
<span class="sig-name descname"><span class="pre">with_fallbacks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">fallbacks:</span> <span class="pre">Sequence[Runnable[Input,</span> <span class="pre">Output]],</span> <span class="pre">*,</span> <span class="pre">exceptions_to_handle:</span> <span class="pre">Tuple[Type[BaseException],</span> <span class="pre">...]</span> <span class="pre">=</span> <span class="pre">(&lt;class</span> <span class="pre">'Exception'&gt;,),</span> <span class="pre">exception_key:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">RunnableWithFallbacksT</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.with_fallbacks" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Add fallbacks to a runnable, returning a new Runnable.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterator</span>

<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableGenerator</span>


<span class="k">def</span> <span class="nf">_generate_immediate_error</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
    <span class="k">yield</span> <span class="s2">&quot;&quot;</span>


<span class="k">def</span> <span class="nf">_generate</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">yield from</span> <span class="s2">&quot;foo bar&quot;</span>


<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableGenerator</span><span class="p">(</span><span class="n">_generate_immediate_error</span><span class="p">)</span><span class="o">.</span><span class="n">with_fallbacks</span><span class="p">(</span>
    <span class="p">[</span><span class="n">RunnableGenerator</span><span class="p">(</span><span class="n">_generate</span><span class="p">)]</span>
    <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">runnable</span><span class="o">.</span><span class="n">stream</span><span class="p">({})))</span> <span class="c1">#foo bar</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fallbacks</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>]</em>) â€“ A sequence of runnables to try if the original runnable fails.</p></li>
<li><p><strong>exceptions_to_handle</strong> (<em>Tuple</em><em>[</em><em>Type</em><em>[</em><em>BaseException</em><em>]</em><em>, </em><em>...</em><em>]</em>) â€“ A tuple of exception types to handle.</p></li>
<li><p><strong>exception_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ If string is specified then handled exceptions will be passed
to fallbacks as part of the input under the specified key. If None,
exceptions will not be passed to fallbacks. If used, the base runnable
and its fallbacks must accept a dictionary as input.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new Runnable that will try the original runnable, and then each
fallback in order, upon failures.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>RunnableWithFallbacksT[Input, Output]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.with_listeners">
<span class="sig-name descname"><span class="pre">with_listeners</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Listener</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_end</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Listener</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_error</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Listener</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.with_listeners" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bind lifecycle listeners to a Runnable, returning a new Runnable.</p>
<p>on_start: Called before the runnable starts running, with the Run object.
on_end: Called after the runnable finishes running, with the Run object.
on_error: Called if the runnable throws an error, with the Run object.</p>
<p>The Run object contains information about the run, including its id,
type, input, output, error, start_time, end_time, and any tags or metadata
added to the run.</p>
<p>Example:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>on_start</strong> (<em>Optional</em><em>[</em><em>Listener</em><em>]</em>) â€“ </p></li>
<li><p><strong>on_end</strong> (<em>Optional</em><em>[</em><em>Listener</em><em>]</em>) â€“ </p></li>
<li><p><strong>on_error</strong> (<em>Optional</em><em>[</em><em>Listener</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable">Runnable</a>[Input, Output]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.with_retry">
<span class="sig-name descname"><span class="pre">with_retry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">retry_if_exception_type:</span> <span class="pre">~typing.Tuple[~typing.Type[BaseException],</span> <span class="pre">...]</span> <span class="pre">=</span> <span class="pre">(&lt;class</span> <span class="pre">'Exception'&gt;,),</span> <span class="pre">wait_exponential_jitter:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">stop_after_attempt:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">3</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.with_retry" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Create a new Runnable that retries the original runnable on exceptions.</p>
<p>Example:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>retry_if_exception_type</strong> (<em>Tuple</em><em>[</em><em>Type</em><em>[</em><em>BaseException</em><em>]</em><em>, </em><em>...</em><em>]</em>) â€“ A tuple of exception types to retry on</p></li>
<li><p><strong>wait_exponential_jitter</strong> (<em>bool</em>) â€“ Whether to add jitter to the wait time
between retries</p></li>
<li><p><strong>stop_after_attempt</strong> (<em>int</em>) â€“ The maximum number of attempts to make before giving up</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new Runnable that retries the original runnable on exceptions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.with_structured_output">
<span class="sig-name descname"><span class="pre">with_structured_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.with_structured_output" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement this if there is a way of steering the model to generate responses that match a given schema.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>Union</em><em>[</em><em>Dict</em><em>, </em><em>Type</em><em>[</em><em>BaseModel</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Union</em>[<a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a>, str, <em>Sequence</em>[<em>Union</em>[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>, <em>Tuple</em>[str, str], str, <em>Dict</em>[str, <em>Any</em>]]]], <em>Union</em>[<em>Dict</em>, <em>BaseModel</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.with_types">
<span class="sig-name descname"><span class="pre">with_types</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.with_types" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bind input and output types to a Runnable, returning a new Runnable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_type</strong> (<em>Optional</em><em>[</em><em>Type</em><em>[</em><em>Input</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>output_type</strong> (<em>Optional</em><em>[</em><em>Type</em><em>[</em><em>Output</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.InputType">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">InputType</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">TypeAlias</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.InputType" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the input type for this runnable.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.OutputType">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">OutputType</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.OutputType" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the output type for this runnable.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.config_specs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config_specs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSpec.html#langchain_core.runnables.utils.ConfigurableFieldSpec" title="langchain_core.runnables.utils.ConfigurableFieldSpec"><span class="pre">ConfigurableFieldSpec</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.config_specs" title="Permalink to this definition">Â¶</a></dt>
<dd><p>List configurable fields for this runnable.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.input_schema">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_schema</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.input_schema" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The type of input this runnable accepts specified as a pydantic model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.lc_attributes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_attributes</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.lc_attributes" title="Permalink to this definition">Â¶</a></dt>
<dd><p>List of attribute names that should be included in the serialized kwargs.</p>
<p>These attributes must be accepted by the constructor.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.lc_secrets">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_secrets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.lc_secrets" title="Permalink to this definition">Â¶</a></dt>
<dd><p>A map of constructor argument names to secret ids.</p>
<dl class="simple">
<dt>For example,</dt><dd><p>{â€œopenai_api_keyâ€: â€œOPENAI_API_KEYâ€}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.name" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The name of the runnable. Used for debugging and tracing.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain_community.chat_models.openai.ChatOpenAI.output_schema">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_schema</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain_community.chat_models.openai.ChatOpenAI.output_schema" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The type of output this runnable produces specified as a pydantic model.</p>
</dd></dl>

</dd></dl>

<h1>Examples using ChatOpenAI<a class="headerlink" href="#langchain-community-chat-models-openai-chatopenai" title="Permalink to this heading">Â¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/chat/token_usage_tracking/">!pip install -qU langchain-openai</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/activeloop/"># activeloop token is needed if you are not signed in using CLI: `activeloop login -u &lt;USERNAME&gt; -p &lt;PASSWORD&gt;`</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/how_to/high_cardinality/">%pip install -qU langchain langchain-community langchain-openai faker langchain-chroma</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/how_to/no_queries/">%pip install -qU langchain langchain-community langchain-openai langchain-chroma</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/quickstart/">%pip install -qU langchain langchain-community langchain-openai youtube-transcript-api pytube langchain-chroma</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/techniques/hyde/">%pip install -qU langchain langchain-openai</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/techniques/structuring/">%pip install -qU langchain langchain-openai youtube-transcript-api pytube</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/techniques/step_back/">%pip install -qU langchain-core langchain-openai</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/uptrain/">1. Vanilla RAG {#vanilla-rag-1}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/evaluation/trajectory/trajectory_eval/">ANTHROPIC_API_KEY=&lt;YOUR ANTHROPIC API KEY&gt;</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/reddit_search/">Adapted code from /docs/modules/agents/how_to/sharedmemory_for_tools</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/primitives/assign/">Adding values to chain state {#adding-values-to-chain-state}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/human_tools/">Answer with â€˜Zhuâ€™</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/e2b_data_analysis/">Artifacts are charts created by matplotlib when `plt.show()` is called</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/multion/">Authorize connection to your Browser extention</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/primitives/binding/">Binding: Attach runtime args {#binding-attach-runtime-args}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever/">Build a sample vectorDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/kdbai/">Clean up KDB.AI â€œdocumentsâ€ table and index for similarity search</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/cnosdb/">CnosDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/primitives/configure/">Configure chain internals at runtime {#configure-chain-internals-at-runtime}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/portkey/logging_tracing_portkey/">Construct the OpenAI Tools agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/evaluation/string/scoring_eval_chain/">Correct</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/csv/">Create a dataframe</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/memgraph/">Creating and executing the seeding query</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/.ipynb_checkpoints/dataherald-checkpoint/">Dataherald</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/development/debugging/">Debugging</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/extraction/how_to/examples/">Define a custom prompt to provide instructions and any additional context.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/python/">Define the neural network</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic/">Define your desired data structure.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/safety/presidio_data_anonymization/index/">Download model</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/extraction/how_to/handle_long_text/">Download the content</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/bearly/">Extract pdf content</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/flyte/">Flyte</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/you/">For use in Chaining section</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/primitives/parallel/">Formatting inputs &amp; output {#formatting-inputs-output}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/max_iterations/">Get the prompt to use - you can modify this!</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/llmlingua/">Helper function for printing docs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/yahoo_finance_news/">How YahooFinanceNewsTool works? {#how-yahoofinancenewstool-works}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/">How many people played in Top Gun?</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/infobip/">How to use it inside an Agent {#how-to-use-it-inside-an-agent}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/ainetwork/">IMPORTANT: If you plan to use this account in the future, make sure to save the</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/tool_use/prompting/">If youâ€™d like to use LangSmith, uncomment the below:</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/evaluation/examples/comparisons/">Initialize the language model</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/extraction/quickstart/">Install a model capable of tool calling</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/yellowbrick/">Install all needed libraries</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/infino/">Install necessary dependencies.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/robocorp/">Install package</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/arangodb/">Instantiate ArangoDB Database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/llmonitor/">LLMonitor</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/agent_structured/">Load in document to retrieve over</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/log10/">Log10</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat_loaders/discord/">Merge consecutive messages from the same sender into a single message</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/index/">Model I/O</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_transformers/openai_metadata_tagger/">Must be an OpenAI model that supports functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/openapi/">NOTE: In this example. We must set `allow_dangerous_request=True` to enable the OpenAPI Agent to automatically use the Request Tool.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/fallbacks/">Note that we set max_retries = 0 to avoid retrying on RateLimits, etc</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/spark_sql/">Note, you can also connect to Spark via Spark connect. For example:</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/flashrank-reranker/">OR  (depending on Python version)</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/platforms/openai/">OpenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/query_analysis/techniques/routing/">Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/streamlit_chat_message_history/">Optionally, specify your own session_state key for storing messages</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/primitives/passthrough/">Passing data through {#passing-data-through}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/neo4jvector/">Pip install necessary package</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/timescalevector/">Pip install necessary packages</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/portkey/index/">Portkey</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/.ipynb_checkpoints/index-checkpoint/">Prompt templates</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/safety/presidio_data_anonymization/qa_privacy_protection/">QA with private data protection {#qa-with-private-data-protection}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/.ipynb_checkpoints/quick_start-checkpoint/">Quickstart</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/quick_start/">Quickstart {#quickstart}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/how_to/message_history/">Remembers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/remembrall/">Remembrall</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/index/">Retrievers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/safety/presidio_data_anonymization/reversible/">Reversible data anonymization with Microsoft Presidio {#reversible-data-anonymization-with-microsoft-presidio}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/primitives/functions/">Run custom functions {#run-custom-functions}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/code_understanding/">Set env var OPENAI_API_KEY or load from a .env file</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/chatbots/memory_management/">Set env var OPENAI_API_KEY or load from a .env file:</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/amadeus/">Set environmental variables here</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/github/">Set your environment variables using os.environ</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/kay/">Setup API key</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/sec_filings/">Setup API keys for Kay and OpenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/momento_vector_index/">Setup {#setup}</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/pandas_dataframe/">Solely for documentation purposes.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/connery/">Specify your Connery Runner credentials.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/interface/">The input schema of the chain is the input schema of its first part, the prompt.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector/">The vectorstore to use to index the child chunks</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/">This example only specifies a filter</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/self_query/tencentvectordb/">This example only specifies a relevant query</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat_loaders/imessage/">This uses some example data</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/per_user/">This will only get documents for Ankush</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/callbacks/async_callbacks/">To enable streaming, we pass in `streaming=True` to the ChatModel constructor</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/citations/">Uncomment if you want to log to LangSmith</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/sql/prompting/">Uncomment the below to use LangSmith. Not required.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/langsmith/walkthrough/">Used by the agent in this tutorial</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/sql/csv/">Using LangSmith is recommended but not required. Uncomment below lines to use.</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat_loaders/langsmith_dataset/">Wait for the fine-tuning to complete (this may take some time)</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/memory/.ipynb_checkpoints/index-checkpoint/">[Beta] Memory</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/memory/adding_memory/">adding_memory.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/airbyte_structured_qa/">airbyte_structured_qa.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/amazon_neptune_open_cypher/">amazon_neptune_open_cypher.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/exa_search/">and some deps for this notebook</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/arthur_tracking/">arthur_tracking.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/arxiv/">arxiv.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/astradb/">astradb.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/bash/">bash.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/why/">batch_configurable_chain([â€œice creamâ€, â€œspaghettiâ€, â€œdumplingsâ€])</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/cassandra/">cassandra.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/chatgpt_plugins/">chatgpt_plugins.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/cookbook/code_writing/">code_writing.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/cogniswitch/">cogniswitch.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/prompts/composition/">composition.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/nebula_graph/">connect ngql jupyter extension to nebulagraph</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/context/">context.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents/">conversational_retrieval_agents.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/tidb_chat_message_history/">copy from tidb cloud console</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/jaguar/">cosine: distance metric</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/csv/">csv.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/productionization/evaluation/trajectory/custom/">custom.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/custom_agent/">custom_agent.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/how_to/decorator/">decorator.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/diffbot/">diffbot.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/document_comparison_toolkit/">document_comparison_toolkit.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/enum/">enum.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/falkordb/">falkordb.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/ontotext/">feeding the schema using a user construct query</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/powerbi/">fictional example</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/fleet_context/">fleet_context.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/vllm/">get a chat completion from the formatted messages</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/arxiv/">get a token: https://platform.openai.com/account/api-keys</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/kuzu_db/">graph.refresh_schema()</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/streaming/">import dotenv</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/how_to/inspect/">inspect.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/weaviate/">install package</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/labelstudio/">labelstudio.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/chat/logprobs/">logprobs.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/cookbook/multiple_chains/">multiple_chains.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/agent_iter/">need to use GPT-4 here as GPT-3.5 does not understand, however hard you insist, that</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/hippo/">openai</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/openai/">openai.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/openai_functions/">openai_functions.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/openai_tools/">openai_tools.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/polygon/">os.environ[â€œLANGCHAIN_TRACING_V2â€] = â€œtrueâ€</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/sql/large_db/">os.environ[â€œOPENAI_API_KEYâ€] = getpass.getpass()</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/outline/">outline.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/output_fixing/">output_fixing.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/pandas/">pandas.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/intermediate_steps/">pip install wikipedia</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser/">prompt_llm_parser.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/expression_language/cookbook/prompt_size/">prompt_size.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/promptlayer/">promptlayer.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/ragatouille/">ragatouille.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/graphs/rdflib_sparql/">rdflib_sparql.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/re_phrase/">re_phrase.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/redis_chat_message_history/">redis_chat_message_history.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/chat/response_metadata/">response_metadata.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/retry/">retry.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_loaders/figma/">see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more details</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_loaders/youtube_audio/">set a flag to switch between local and remote parsing</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/sql_database/">sql_database.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/semanticscholar/">start by installing semanticscholar api</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/types/structured/">structured.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/chat/structured_output/">structured_output.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/tools/tools_as_openai_functions/">tools_as_openai_functions.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/trubrics/">trubrics.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/xata_chat_message_history/">xata_chat_message_history.md</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/langserve/">ðŸ¦œï¸ðŸ“ LangServe</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/langgraph/">ðŸ¦œðŸ•¸ï¸LangGraph</a></p></li>
</ul>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2023, LangChain, Inc..
          Last updated on Apr 30, 2024.
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>
<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">Â¶</a>');
	});
});

</script>
    
</body>
</html>