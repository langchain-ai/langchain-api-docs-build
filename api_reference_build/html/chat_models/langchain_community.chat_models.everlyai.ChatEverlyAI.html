

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en"> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    
        <title>langchain_community.chat_models.everlyai.ChatEverlyAI &mdash; ü¶úüîó LangChain 0.2.5</title>
    
    <link rel="canonical"
          href="https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.everlyai.ChatEverlyAI.html"/>

    

    <link rel="stylesheet"
          href="../_static/css/vendor/bootstrap.min.css"
          type="text/css"/>
            <link rel="stylesheet" href="../_static/pygments.css" type="text/css"/>
            <link rel="stylesheet" href="../_static/css/theme.css" type="text/css"/>
            <link rel="stylesheet" href="../_static/autodoc_pydantic.css" type="text/css"/>
            <link rel="stylesheet" href="../_static/copybutton.css" type="text/css"/>
            <link rel="stylesheet" href="../_static/sphinx-dropdown.css" type="text/css"/>
            <link rel="stylesheet" href="../_static/panels-bootstrap.min.css" type="text/css"/>
            <link rel="stylesheet" href="../_static/css/custom.css" type="text/css"/>
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css"/>
    <script id="documentation_options" data-url_root="../"
            src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script> 
</head>
<body>


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../langchain_api_reference.html">LangChain</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../core_api_reference.html">Core</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../community_api_reference.html">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../experimental_api_reference.html">Experimental</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../text_splitters_api_reference.html">Text splitters</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../ai21_api_reference.html">ai21</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../airbyte_api_reference.html">airbyte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../anthropic_api_reference.html">anthropic</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../astradb_api_reference.html">astradb</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../aws_api_reference.html">aws</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../azure_dynamic_sessions_api_reference.html">azure-dynamic-sessions</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../chroma_api_reference.html">chroma</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../cohere_api_reference.html">cohere</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../couchbase_api_reference.html">couchbase</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../elasticsearch_api_reference.html">elasticsearch</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../exa_api_reference.html">exa</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../fireworks_api_reference.html">fireworks</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../google_genai_api_reference.html">google-genai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../google_vertexai_api_reference.html">google-vertexai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../groq_api_reference.html">groq</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../huggingface_api_reference.html">huggingface</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../ibm_api_reference.html">ibm</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../milvus_api_reference.html">milvus</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../mistralai_api_reference.html">mistralai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../mongodb_api_reference.html">mongodb</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../nomic_api_reference.html">nomic</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../nvidia_ai_endpoints_api_reference.html">nvidia-ai-endpoints</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../openai_api_reference.html">openai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../pinecone_api_reference.html">pinecone</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../postgres_api_reference.html">postgres</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../prompty_api_reference.html">prompty</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../qdrant_api_reference.html">qdrant</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../robocorp_api_reference.html">robocorp</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../together_api_reference.html">together</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../voyageai_api_reference.html">voyageai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../weaviate_api_reference.html">weaviate</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Partner libs</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../ai21_api_reference.html">ai21</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../airbyte_api_reference.html">airbyte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../anthropic_api_reference.html">anthropic</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../astradb_api_reference.html">astradb</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../aws_api_reference.html">aws</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../azure_dynamic_sessions_api_reference.html">azure-dynamic-sessions</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../chroma_api_reference.html">chroma</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../cohere_api_reference.html">cohere</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../couchbase_api_reference.html">couchbase</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../elasticsearch_api_reference.html">elasticsearch</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../exa_api_reference.html">exa</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../fireworks_api_reference.html">fireworks</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../google_genai_api_reference.html">google-genai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../google_vertexai_api_reference.html">google-vertexai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../groq_api_reference.html">groq</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../huggingface_api_reference.html">huggingface</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../ibm_api_reference.html">ibm</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../milvus_api_reference.html">milvus</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../mistralai_api_reference.html">mistralai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../mongodb_api_reference.html">mongodb</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../nomic_api_reference.html">nomic</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../nvidia_ai_endpoints_api_reference.html">nvidia-ai-endpoints</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../openai_api_reference.html">openai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../pinecone_api_reference.html">pinecone</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../postgres_api_reference.html">postgres</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../prompty_api_reference.html">prompty</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../qdrant_api_reference.html">qdrant</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../robocorp_api_reference.html">robocorp</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../together_api_reference.html">together</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../voyageai_api_reference.html">voyageai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../weaviate_api_reference.html">weaviate</a>
          </div>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://python.langchain.com/">Docs</a>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
    <div class="d-flex" id="sk-doc-wrapper">
        <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
        <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary"
               for="sk-toggle-checkbox">Toggle Menu</label>
        <div id="sk-sidebar-wrapper" class="border-right">
            <div class="sk-sidebar-toc-wrapper">
                    <div class="sk-sidebar-toc">
                        <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain_community.chat_models.everlyai</span></code>.ChatEverlyAI</a><ul>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI</span></code></a><ul>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.available_models"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.available_models</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.cache"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.cache</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.callback_manager"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.callback_manager</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.callbacks"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.callbacks</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.custom_get_token_ids"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.custom_get_token_ids</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.default_headers"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.default_headers</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.default_query"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.default_query</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.everlyai_api_base"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.everlyai_api_base</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.everlyai_api_key"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.everlyai_api_key</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.http_client"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.http_client</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.max_retries"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.max_retries</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.max_tokens"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.max_tokens</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.metadata"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.metadata</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.model_kwargs"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.model_kwargs</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.model_name"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.model_name</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.n"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.n</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_api_base"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.openai_api_base</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_api_key"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.openai_api_key</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_organization"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.openai_organization</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_proxy"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.openai_proxy</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.request_timeout"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.request_timeout</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.streaming"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.streaming</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.tags"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.tags</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.temperature"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.temperature</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.tiktoken_model_name"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.tiktoken_model_name</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.verbose"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.verbose</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.__call__"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.__call__()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.agenerate"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.agenerate()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.agenerate_prompt"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.agenerate_prompt()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.apredict"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.apredict()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.apredict_messages"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.apredict_messages()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.bind_functions"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.bind_functions()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.bind_tools"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.bind_tools()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.call_as_llm"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.call_as_llm()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.completion_with_retry"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.completion_with_retry()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.generate"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.generate()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.generate_prompt"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.generate_prompt()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_available_models"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.get_available_models()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_num_tokens"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.get_num_tokens()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_num_tokens_from_messages"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.get_num_tokens_from_messages()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_token_ids"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.get_token_ids()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.predict"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.predict()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.predict_messages"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.predict_messages()</span></code></a></li>
<li><a class="reference internal" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.with_structured_output"><code class="docutils literal notranslate"><span class="pre">ChatEverlyAI.with_structured_output()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

                    </div>
            </div>
        </div>
        <div id="sk-page-content-wrapper">
            <div class="sk-page-content container-fluid body px-md-3" role="main">
                
  <section id="langchain-community-chat-models-everlyai-chateverlyai">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain_community.chat_models.everlyai</span></code>.ChatEverlyAI<a class="headerlink" href="#langchain-community-chat-models-everlyai-chateverlyai" title="Permalink to this heading">¬∂</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ChatEverlyAI implements the standard <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span> <span class="pre">Interface</span></code></a>. üèÉ</p>
</div>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain_community.chat_models.everlyai.</span></span><span class="sig-name descname"><span class="pre">ChatEverlyAI</span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/everlyai.html#ChatEverlyAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Bases: <a class="reference internal" href="langchain_community.chat_models.openai.ChatOpenAI.html#langchain_community.chat_models.openai.ChatOpenAI" title="langchain_community.chat_models.openai.ChatOpenAI"><code class="xref py py-class docutils literal notranslate"><span class="pre">ChatOpenAI</span></code></a></p>
<p><cite>EverlyAI</cite> Chat large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">EVERLYAI_API_KEY</span></code> set with your API key.
Alternatively, you can use the everlyai_api_key keyword argument.</p>
<p>Any parameters that are valid to be passed to the <cite>openai.create</cite> call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.chat_models</span> <span class="kn">import</span> <span class="n">ChatEverlyAI</span>
<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatEverlyAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.available_models">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">available_models</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.available_models" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Available models from EverlyAI API.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.cache">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../caches/langchain_core.caches.BaseCache.html#langchain_core.caches.BaseCache" title="langchain_core.caches.BaseCache"><span class="pre">BaseCache</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.cache" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Whether to cache the response.</p>
<ul class="simple">
<li><p>If true, will use the global cache.</p></li>
<li><p>If false, will not use a cache</p></li>
<li><p>If None, will use the global cache if it‚Äôs set, otherwise no cache.</p></li>
<li><p>If instance of BaseCache, will use the provided cache.</p></li>
</ul>
<p>Caching is not currently supported for streaming methods of models.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.callback_manager">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">callback_manager</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.callback_manager" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[DEPRECATED] Callback manager to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.callbacks">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">callbacks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callbacks</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.callbacks" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Callbacks to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.custom_get_token_ids">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">custom_get_token_ids</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.custom_get_token_ids" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Optional encoder to use for counting tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.default_headers">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_headers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.default_headers" title="Permalink to this definition">¬∂</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.default_query">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_query</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.default_query" title="Permalink to this definition">¬∂</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.everlyai_api_base">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">everlyai_api_base</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'https://everlyai.xyz/hosted'</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.everlyai_api_base" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Base URL path for API requests.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.everlyai_api_key">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">everlyai_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.everlyai_api_key" title="Permalink to this definition">¬∂</a></dt>
<dd><p>EverlyAI Endpoints API keys.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.http_client">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">http_client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.http_client" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Optional httpx.Client.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.max_retries">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.max_retries" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.max_tokens">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.max_tokens" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.metadata">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.metadata" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Metadata to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.model_kwargs">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.model_kwargs" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.model_name">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'meta-llama/Llama-2-7b-chat-hf'</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'model')</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.model_name" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.n">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.n" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Number of chat completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.openai_api_base">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_api_base</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'base_url')</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_api_base" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Base URL path for API requests, leave blank if not using a proxy or service
emulator.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.openai_api_key">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'api_key')</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_api_key" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Automatically inferred from env var <cite>OPENAI_API_KEY</cite> if not provided.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.openai_organization">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_organization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'organization')</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_organization" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Automatically inferred from env var <cite>OPENAI_ORG_ID</cite> if not provided.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.openai_proxy">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_proxy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.openai_proxy" title="Permalink to this definition">¬∂</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.request_timeout">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'timeout')</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.request_timeout" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Timeout for requests to OpenAI completion API. Can be float, httpx.Timeout or
None.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.streaming">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.streaming" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.tags">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.tags" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Tags to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.temperature">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.temperature" title="Permalink to this definition">¬∂</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.tiktoken_model_name">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tiktoken_model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.tiktoken_model_name" title="Permalink to this definition">¬∂</a></dt>
<dd><p>The model name to pass to tiktoken when using this class.
Tiktoken is used to count the number of tokens in documents to constrain
them to be under a certain limit. By default, when set to None, this will
be the same as the embedding model name. However, there are some cases
where you may want to use this Embedding class with a model name not
supported by tiktoken. This can include when using Azure embeddings or
when using one of the many model providers that expose an OpenAI-like
API but with different models. In those cases, in order to avoid erroring
when tiktoken is called, you can specify a model name to use here.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.verbose">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.verbose" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.__call__" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) ‚Äì </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">UUID</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.agenerate" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Asynchronously pass a sequence of prompts to a model and return generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em><em>]</em>) ‚Äì List of list of messages.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) ‚Äì Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>metadata</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>run_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>run_id</strong> (<em>Optional</em><em>[</em><em>UUID</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>**kwargs</strong> ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.agenerate_prompt" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Asynchronously pass a sequence of prompts and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a><em>]</em>) ‚Äì List of PromptValues. A PromptValue is an object that can be
converted to match the format of any language model (string for pure
text generation models and BaseMessages for chat models).</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) ‚Äì Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.apredict" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use ainvoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) ‚Äì </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.apredict_messages" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use ainvoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) ‚Äì </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.bind_functions">
<span class="sig-name descname"><span class="pre">bind_functions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">function_call</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.bind_functions" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Bind functions (and other objects) to this chat model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>functions</strong> (<em>Sequence</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Type</em><em>[</em><em>BaseModel</em><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) ‚Äì A list of function definitions to bind to this chat model.
Can be  a dictionary, pydantic model, or callable. Pydantic
models and callables will be automatically converted to
their schema dictionary representation.</p></li>
<li><p><strong>function_call</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) ‚Äì Which function to require the model to call.
Must be the name of the single provided function or
‚Äúauto‚Äù to automatically determine which function to call
(if any).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì Any additional parameters to pass to the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span></code> constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Union</em>[<a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a>, str, <em>Sequence</em>[<em>Union</em>[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>, <em>List</em>[str], <em>Tuple</em>[str, str], str, <em>Dict</em>[str, <em>Any</em>]]]], <a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.bind_tools">
<span class="sig-name descname"><span class="pre">bind_tools</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tools</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../vectorstores/langchain_community.vectorstores.pgembedding.BaseModel.html#langchain_community.vectorstores.pgembedding.BaseModel" title="langchain_community.vectorstores.pgembedding.BaseModel"><span class="pre">BaseModel</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool" title="langchain_core.tools.BaseTool"><span class="pre">BaseTool</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">LanguageModelInput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.bind_tools" title="Permalink to this definition">¬∂</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tools</strong> (<em>Sequence</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Type</em><em>[</em><a class="reference internal" href="../vectorstores/langchain_community.vectorstores.pgembedding.BaseModel.html#langchain_community.vectorstores.pgembedding.BaseModel" title="langchain_community.vectorstores.pgembedding.BaseModel"><em>BaseModel</em></a><em>]</em><em>, </em><em>Callable</em><em>, </em><a class="reference internal" href="../tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool" title="langchain_core.tools.BaseTool"><em>BaseTool</em></a><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable">Runnable</a>[LanguageModelInput, <a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage">BaseMessage</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.call_as_llm">
<span class="sig-name descname"><span class="pre">call_as_llm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.call_as_llm" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>message</strong> (<em>str</em>) ‚Äì </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.completion_with_retry">
<span class="sig-name descname"><span class="pre">completion_with_retry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_manager</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.manager.CallbackManagerForLLMRun.html#langchain_core.callbacks.manager.CallbackManagerForLLMRun" title="langchain_core.callbacks.manager.CallbackManagerForLLMRun"><span class="pre">CallbackManagerForLLMRun</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.completion_with_retry" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Use tenacity to retry the completion call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>run_manager</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.manager.CallbackManagerForLLMRun.html#langchain_core.callbacks.manager.CallbackManagerForLLMRun" title="langchain_core.callbacks.manager.CallbackManagerForLLMRun"><em>CallbackManagerForLLMRun</em></a><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Any</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">UUID</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.generate" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Pass a sequence of prompts to the model and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em><em>]</em>) ‚Äì List of list of messages.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) ‚Äì Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>metadata</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>run_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>run_id</strong> (<em>Optional</em><em>[</em><em>UUID</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>**kwargs</strong> ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.generate_prompt" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Pass a sequence of prompts to the model and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a><em>]</em>) ‚Äì List of PromptValues. A PromptValue is an object that can be
converted to match the format of any language model (string for pure
text generation models and BaseMessages for chat models).</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler" title="langchain_core.callbacks.base.BaseCallbackHandler"><em>BaseCallbackHandler</em></a><em>]</em><em>, </em><a class="reference internal" href="../callbacks/langchain_core.callbacks.base.BaseCallbackManager.html#langchain_core.callbacks.base.BaseCallbackManager" title="langchain_core.callbacks.base.BaseCallbackManager"><em>BaseCallbackManager</em></a><em>]</em><em>]</em>) ‚Äì Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult" title="langchain_core.outputs.llm_result.LLMResult"><em>LLMResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.get_available_models">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_available_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/everlyai.html#ChatEverlyAI.get_available_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_available_models" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Get available models from EverlyAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Set</em>[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_num_tokens" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<p>Useful for checking if an input will fit in a model‚Äôs context window.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) ‚Äì The string input to tokenize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The integer number of tokens in the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">langchain_core.messages.base.BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../_modules/langchain_community/chat_models/everlyai.html#ChatEverlyAI.get_num_tokens_from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_num_tokens_from_messages" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Calculate num tokens with tiktoken package.</p>
<p>Official documentation: <a class="reference external" href="https://github.com/openai/openai-cookbook/blob/">https://github.com/openai/openai-cookbook/blob/</a>
main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>list</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>langchain_core.messages.base.BaseMessage</em></a><em>]</em>) ‚Äì </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.get_token_ids" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Get the tokens present in the text with tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) ‚Äì </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.predict" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) ‚Äì </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.predict_messages" title="Permalink to this definition">¬∂</a></dt>
<dd><p>[<em>Deprecated</em>]</p>
<p class="rubric">Notes</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.1.7: </span>Use invoke instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em>]</em>) ‚Äì </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_community.chat_models.everlyai.ChatEverlyAI.with_structured_output">
<span class="sig-name descname"><span class="pre">with_structured_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../vectorstores/langchain_community.vectorstores.pgembedding.BaseModel.html#langchain_community.vectorstores.pgembedding.BaseModel" title="langchain_community.vectorstores.pgembedding.BaseModel"><span class="pre">BaseModel</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_raw</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">LanguageModelInput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../vectorstores/langchain_community.vectorstores.pgembedding.BaseModel.html#langchain_community.vectorstores.pgembedding.BaseModel" title="langchain_community.vectorstores.pgembedding.BaseModel"><span class="pre">BaseModel</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_community.chat_models.everlyai.ChatEverlyAI.with_structured_output" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Model wrapper that returns outputs formatted to match the given schema.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>Union</em><em>[</em><em>Dict</em><em>, </em><em>Type</em><em>[</em><a class="reference internal" href="../vectorstores/langchain_community.vectorstores.pgembedding.BaseModel.html#langchain_community.vectorstores.pgembedding.BaseModel" title="langchain_community.vectorstores.pgembedding.BaseModel"><em>BaseModel</em></a><em>]</em><em>]</em>) ‚Äì The output schema as a dict or a Pydantic class. If a Pydantic class
then the model output will be an object of that class. If a dict then
the model output will be a dict. With a Pydantic class the returned
attributes will be validated, whereas with a dict they will not be. If
<cite>method</cite> is ‚Äúfunction_calling‚Äù and <cite>schema</cite> is a dict, then the dict
must match the OpenAI function-calling spec.</p></li>
<li><p><strong>include_raw</strong> (<em>bool</em>) ‚Äì If False then only the parsed structured output is returned. If
an error occurs during model output parsing it will be raised. If True
then both the raw model response (a BaseMessage) and the parsed model
response will be returned. If an error occurs during output parsing it
will be caught and returned as well. The final output is always a dict
with keys ‚Äúraw‚Äù, ‚Äúparsed‚Äù, and ‚Äúparsing_error‚Äù.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>If include_raw is True then a dict with keys:</dt><dd><p>raw: BaseMessage
parsed: Optional[_DictOrPydantic]
parsing_error: Optional[BaseException]</p>
</dd>
</dl>
<p>If include_raw is False then just _DictOrPydantic is returned,
where _DictOrPydantic depends on the schema:</p>
<dl class="simple">
<dt>If schema is a Pydantic class then _DictOrPydantic is the Pydantic</dt><dd><p>class.</p>
</dd>
</dl>
<p>If schema is a dict then _DictOrPydantic is a dict.</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A Runnable that takes any ChatModel input and returns as output</p>
</dd>
</dl>
<dl>
<dt>Example: Function-calling, Pydantic schema (method=‚Äùfunction_calling‚Äù, include_raw=False):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span>

<span class="k">class</span> <span class="nc">AnswerWithJustification</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;An answer to the user question along with justification for the answer.&#39;&#39;&#39;</span>
    <span class="n">answer</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">justification</span><span class="p">:</span> <span class="nb">str</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;model-name&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">with_structured_output</span><span class="p">(</span><span class="n">AnswerWithJustification</span><span class="p">)</span>

<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;What weighs more a pound of bricks or a pound of feathers&quot;</span><span class="p">)</span>

<span class="c1"># -&gt; AnswerWithJustification(</span>
<span class="c1">#     answer=&#39;They weigh the same&#39;,</span>
<span class="c1">#     justification=&#39;Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.&#39;</span>
<span class="c1"># )</span>
</pre></div>
</div>
</dd>
<dt>Example: Function-calling, Pydantic schema (method=‚Äùfunction_calling‚Äù, include_raw=True):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span>

<span class="k">class</span> <span class="nc">AnswerWithJustification</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;An answer to the user question along with justification for the answer.&#39;&#39;&#39;</span>
    <span class="n">answer</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">justification</span><span class="p">:</span> <span class="nb">str</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;model-name&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">with_structured_output</span><span class="p">(</span><span class="n">AnswerWithJustification</span><span class="p">,</span> <span class="n">include_raw</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;What weighs more a pound of bricks or a pound of feathers&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; {</span>
<span class="c1">#     &#39;raw&#39;: AIMessage(content=&#39;&#39;, additional_kwargs={&#39;tool_calls&#39;: [{&#39;id&#39;: &#39;call_Ao02pnFYXD6GN1yzc0uXPsvF&#39;, &#39;function&#39;: {&#39;arguments&#39;: &#39;{&quot;answer&quot;:&quot;They weigh the same.&quot;,&quot;justification&quot;:&quot;Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.&quot;}&#39;, &#39;name&#39;: &#39;AnswerWithJustification&#39;}, &#39;type&#39;: &#39;function&#39;}]}),</span>
<span class="c1">#     &#39;parsed&#39;: AnswerWithJustification(answer=&#39;They weigh the same.&#39;, justification=&#39;Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.&#39;),</span>
<span class="c1">#     &#39;parsing_error&#39;: None</span>
<span class="c1"># }</span>
</pre></div>
</div>
</dd>
<dt>Example: Function-calling, dict schema (method=‚Äùfunction_calling‚Äù, include_raw=False):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">langchain_core.utils.function_calling</span> <span class="kn">import</span> <span class="n">convert_to_openai_tool</span>

<span class="k">class</span> <span class="nc">AnswerWithJustification</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;An answer to the user question along with justification for the answer.&#39;&#39;&#39;</span>
    <span class="n">answer</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">justification</span><span class="p">:</span> <span class="nb">str</span>

<span class="n">dict_schema</span> <span class="o">=</span> <span class="n">convert_to_openai_tool</span><span class="p">(</span><span class="n">AnswerWithJustification</span><span class="p">)</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;model-name&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">with_structured_output</span><span class="p">(</span><span class="n">dict_schema</span><span class="p">)</span>

<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;What weighs more a pound of bricks or a pound of feathers&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; {</span>
<span class="c1">#     &#39;answer&#39;: &#39;They weigh the same&#39;,</span>
<span class="c1">#     &#39;justification&#39;: &#39;Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume and density of the two substances differ.&#39;</span>
<span class="c1"># }</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

<h1>Examples using ChatEverlyAI<a class="headerlink" href="#langchain-community-chat-models-everlyai-chateverlyai" title="Permalink to this heading">¬∂</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/everlyai/">ChatEverlyAI</a></p></li>
</ul>
</section>


            </div>
            <div class="container">
                <footer class="sk-content-footer">
                                &copy; 2023, LangChain, Inc.
                                    .
                            Last updated
                                on Jun 21, 2024.
                </footer>
            </div>
        </div>
    </div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>
<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¬∂</a>');
	});
});

</script>
    
</body>
</html>